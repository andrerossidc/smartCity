{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento com o modelo Mask-RCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.visualize import display_instances\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "\n",
    "ROOT_DIR = \"./maskrcnn_model/\"\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuração para treinamento no conjunto de dados \n",
    "class COCOConfig(Config):\n",
    "    NAME = \"CocoDataset_config\"\n",
    "\n",
    "    IMAGES_PER_GPU = 40\n",
    "\n",
    "    NUM_CLASSES = 1 + 80  # Background + restante das classes\n",
    "\n",
    "    #Número de etapas de treinamento por época\n",
    "    STEPS_PER_EPOCH = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#método para obter os nomes das classes\n",
    "def class_name():\n",
    "    path = open(\"./annotations/instances_train2017.json\", \"r\")\n",
    "    anns = json.load(path)\n",
    "    name_cat = []\n",
    "\n",
    "    for name in anns['categories']['name']:\n",
    "        name_cat.append(name)\n",
    "\n",
    "    return name_cat\n",
    "\n",
    "#método para obter os ids das classes\n",
    "def class_id():\n",
    "    path = open(\"./annotations/instances_train2017.json\", \"r\")\n",
    "    anns = json.load(path)\n",
    "    id_cat = []\n",
    "\n",
    "    for id in anns['categories']['id']:\n",
    "        id_cat.append(id)\n",
    "        \n",
    "    return id_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nessa classe se inicia a personalização do conjunto de dados\n",
    "class COCODataset(utils.Dataset):\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        source_name = \"object\"\n",
    "\n",
    "        #criando as variaveis que contém o id das categorias e os nomes\n",
    "        id_cat=list, name_cat= list\n",
    "        id_cat = class_id()\n",
    "        name_cat = class_name()\n",
    "\n",
    "        #adicionando as categorias na classe\n",
    "        for x in range(0, 79):\n",
    "            self.add_class(source_name, id_cat[x], name_cat[x])\n",
    "\n",
    "        #adicionando os dados pertencentes às imgs de treino\n",
    "        if(subset == \"train\"):\n",
    "            annot = json.load(open('./annotations/instances_train2017.json'))       \n",
    "            images_dir = dataset_dir + 'images/train/all_images'\n",
    "            #obtendo o filename da imagem\n",
    "            for filename in os.listdir(images_dir):\n",
    "                image_id = filename[:-4]\n",
    "\n",
    "        #adicionando os dados pertencentes às imgs de validação\n",
    "        else:\n",
    "            annot = json.load(open('./annotations/instances_val2017.json'))\n",
    "            images_dir = dataset_dir + 'images/val/all_images'\n",
    "            #obtendo o filename da imagem\n",
    "            for filename in os.listdir(images_dir):\n",
    "                image_id = filename[:-4]\n",
    "\n",
    "        #carregando informações da imagem\n",
    "        img_path = images_dir + filename\n",
    "        ann_img = annot['annotations'][image_id]['image_id']\n",
    "        image_width = image_id['width']\n",
    "        image_height = image_id['height']\n",
    "               \n",
    "        \n",
    "        self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=img_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=ann_img\n",
    "                )\n",
    "\n",
    "    #Carregando máscaras de instância para a imagem fornecida\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotations']\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            class_id = annotation['category_id']\n",
    "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
    "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "            for segmentation in annotation['segmentation']:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "                bool_array = np.array(mask) > 0\n",
    "                instance_masks.append(bool_array)\n",
    "                class_ids.append(class_id)\n",
    " \n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        \n",
    "        return mask, class_ids\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iniciando o treinamento\n",
    "train_dataset = COCODataset()\n",
    "train_dataset.load_dataset(dataset_dir='./BD/', subset='train')\n",
    "train_dataset.prepare()\n",
    "\n",
    "#iniciando a validação\n",
    "val_dataset = COCODataset()\n",
    "val_dataset.load_dataset(dataset_dir='./BD/', subset='val')\n",
    "val_dataset.prepare()\n",
    "\n",
    "\n",
    "config = COCOConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "start_train = time.time()\n",
    "model.train(train_dataset=train_dataset, \n",
    "            val_dataset=val_dataset, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisão média (mAP) - TREINAMENTO\n",
    "total_gt = np.array([]) \n",
    "total_pred = np.array([]) \n",
    "mAP_ = [] #mAP list\n",
    "\n",
    "\n",
    "for image_id in train_dataset.image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(train_dataset, config, image_id)\n",
    "    info = train_dataset.image_info[image_id]\n",
    "\n",
    "    #percorrendo o modelo\n",
    "    results = model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "    \n",
    "    #compute gt_tot and pred_tot\n",
    "    gt, pred = utils.gt_pred_lists(gt_class_id, gt_bbox, r['class_ids'], r['rois'])\n",
    "    total_gt = np.append(total_gt, gt)\n",
    "    total_pred = np.append(total_pred, pred)\n",
    "    \n",
    "    #precision_, recall_, AP_ \n",
    "    AP_, precision_, recall_, overlap_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "\n",
    "\n",
    "    print(\"O atual comprimento do vetor de previsão é: \", len(total_pred))\n",
    "    \n",
    "    mAP_.append(AP_)\n",
    "    print(\"Precisão média desta imagem: \",AP_)\n",
    "    print(\"A precisão média real para todas as imagens de treino é:\", sum(mAP_)/len(mAP_))\n",
    "\n",
    "import pandas as pd\n",
    "total_gt=total_gt.astype(int)\n",
    "total_pred=total_pred.astype(int)\n",
    "#salvando os vetores de gt e pred\n",
    "save_dir = \"output\"\n",
    "gt_pred_tot_json = {\"Verdade total\" : total_gt, \"caixa prevista\" : total_pred}\n",
    "df = pd.DataFrame(gt_pred_tot_json)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "df.to_json(os.path.join(save_dir,\"gt_pred_test.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisão média (mAP) - VALIDAÇÃO\n",
    "total_gt = np.array([]) \n",
    "total_pred = np.array([]) \n",
    "mAP_ = [] #mAP list\n",
    "\n",
    "\n",
    "for image_id in val_dataset.image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(val_dataset, config, image_id)\n",
    "    info = val_dataset.image_info[image_id]\n",
    "\n",
    "    #percorrendo o modelo\n",
    "    results = model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "    \n",
    "    #compute gt_tot and pred_tot\n",
    "    gt, pred = utils.gt_pred_lists(gt_class_id, gt_bbox, r['class_ids'], r['rois'])\n",
    "    total_gt = np.append(total_gt, gt)\n",
    "    total_pred = np.append(total_pred, pred)\n",
    "    \n",
    "    #precision_, recall_, AP_ \n",
    "    AP_, precision_, recall_, overlap_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "\n",
    "\n",
    "    print(\"O atual comprimento do vetor de previsão é: \", len(total_pred))\n",
    "    \n",
    "    mAP_.append(AP_)\n",
    "    print(\"Precisão média desta imagem: \",AP_)\n",
    "    print(\"A precisão média real para todas as imagens de validação é:\", sum(mAP_)/len(mAP_))\n",
    "\n",
    "import pandas as pd\n",
    "total_gt=total_gt.astype(int)\n",
    "total_pred=total_pred.astype(int)\n",
    "#salvando os vetores de gt e pred\n",
    "save_dir = \"output\"\n",
    "gt_pred_tot_json = {\"Verdade total\" : total_gt, \"caixa prevista\" : total_pred}\n",
    "df = pd.DataFrame(gt_pred_tot_json)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "df.to_json(os.path.join(save_dir,\"gt_pred_val.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6aa5dce5059a453159e2a57ed60d810b25a83b0488ffa47056eaa991d05d3cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
